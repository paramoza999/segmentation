{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20848b48-138e-4697-b365-8d2acc8bd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7bc38c-c12c-4e9a-b4f9-c6f08d7ccda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "<__main__.parse_args.<locals>.Args object at 0x155550269210>\n",
      "start loading training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0872371 1.1862054 1.        1.7367345 2.126663  2.0220127 1.788688\n",
      " 1.8918622 2.0941825 4.048591  1.7390136 2.4426463 1.2522498]\n",
      "Totally 7363 samples in train set.\n",
      "start loading test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3699402 1.4154122 1.              inf 7.784936        inf 1.9372996\n",
      " 2.1385393 2.7646968       inf 2.5357857       inf 1.3914901]\n",
      "Totally 1180 samples in test set.\n",
      "The number of training data is: 7363\n",
      "The number of test data is: 1180\n",
      "Use pretrain model\n",
      "**** Epoch 1 (3/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [04:54<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.327989\n",
      "Training accuracy: 0.891671\n",
      "---- EPOCH 001 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:34<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.716795\n",
      "eval point avg class IoU: 0.299393\n",
      "eval point accuracy: 0.654940\n",
      "eval point avg class acc: 0.400256\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.152, IoU: 0.620 \n",
      "class floor          weight: 0.160, IoU: 0.840 \n",
      "class wall           weight: 0.138, IoU: 0.599 \n",
      "class beam           weight: 0.407, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.473 \n",
      "class table          weight: 0.053, IoU: 0.346 \n",
      "class chair          weight: 0.044, IoU: 0.564 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.253 \n",
      "class board          weight: 0.024, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.197 \n",
      "\n",
      "Eval mean loss: 1.716795\n",
      "Eval accuracy: 0.654940\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_parallel/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.299393\n",
      "**** Epoch 2 (4/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:52<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.293562\n",
      "Training accuracy: 0.900969\n",
      "---- EPOCH 002 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:33<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.581044\n",
      "eval point avg class IoU: 0.275556\n",
      "eval point accuracy: 0.621558\n",
      "eval point avg class acc: 0.384282\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.154, IoU: 0.521 \n",
      "class floor          weight: 0.167, IoU: 0.846 \n",
      "class wall           weight: 0.149, IoU: 0.574 \n",
      "class beam           weight: 0.394, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.004 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.401 \n",
      "class table          weight: 0.049, IoU: 0.322 \n",
      "class chair          weight: 0.042, IoU: 0.534 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.172 \n",
      "class board          weight: 0.025, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.207 \n",
      "\n",
      "Eval mean loss: 1.581044\n",
      "Eval accuracy: 0.621558\n",
      "Best mIoU: 0.299393\n",
      "**** Epoch 3 (5/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:53<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.268561\n",
      "Training accuracy: 0.908148\n",
      "---- EPOCH 003 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:33<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.938032\n",
      "eval point avg class IoU: 0.270331\n",
      "eval point accuracy: 0.608450\n",
      "eval point avg class acc: 0.367578\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.156, IoU: 0.471 \n",
      "class floor          weight: 0.167, IoU: 0.799 \n",
      "class wall           weight: 0.148, IoU: 0.584 \n",
      "class beam           weight: 0.382, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.004 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.459 \n",
      "class table          weight: 0.053, IoU: 0.330 \n",
      "class chair          weight: 0.045, IoU: 0.409 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.256 \n",
      "class board          weight: 0.027, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.202 \n",
      "\n",
      "Eval mean loss: 1.938032\n",
      "Eval accuracy: 0.608450\n",
      "Best mIoU: 0.299393\n",
      "**** Epoch 4 (6/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:53<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.255293\n",
      "Training accuracy: 0.913339\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_parallel/checkpoints/model.pth\n",
      "Saving model....\n",
      "---- EPOCH 004 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:34<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.765803\n",
      "eval point avg class IoU: 0.298631\n",
      "eval point accuracy: 0.672507\n",
      "eval point avg class acc: 0.390785\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.158, IoU: 0.592 \n",
      "class floor          weight: 0.167, IoU: 0.830 \n",
      "class wall           weight: 0.148, IoU: 0.626 \n",
      "class beam           weight: 0.380, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.512 \n",
      "class table          weight: 0.054, IoU: 0.379 \n",
      "class chair          weight: 0.045, IoU: 0.405 \n",
      "class sofa           weight: 0.021, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.275 \n",
      "class board          weight: 0.027, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.261 \n",
      "\n",
      "Eval mean loss: 1.765803\n",
      "Eval accuracy: 0.672507\n",
      "Best mIoU: 0.299393\n",
      "**** Epoch 5 (7/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:55<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.234243\n",
      "Training accuracy: 0.920166\n",
      "---- EPOCH 005 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:34<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.518222\n",
      "eval point avg class IoU: 0.302337\n",
      "eval point accuracy: 0.666123\n",
      "eval point avg class acc: 0.412166\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.151, IoU: 0.566 \n",
      "class floor          weight: 0.163, IoU: 0.827 \n",
      "class wall           weight: 0.145, IoU: 0.635 \n",
      "class beam           weight: 0.394, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.008 \n",
      "class window         weight: 0.000, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.511 \n",
      "class table          weight: 0.054, IoU: 0.399 \n",
      "class chair          weight: 0.049, IoU: 0.517 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.252 \n",
      "class board          weight: 0.023, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.217 \n",
      "\n",
      "Eval mean loss: 1.518222\n",
      "Eval accuracy: 0.666123\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_parallel/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.302337\n",
      "**** Epoch 6 (8/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:52<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.234304\n",
      "Training accuracy: 0.919759\n",
      "---- EPOCH 006 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:33<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.491745\n",
      "eval point avg class IoU: 0.291924\n",
      "eval point accuracy: 0.624739\n",
      "eval point avg class acc: 0.402514\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.155, IoU: 0.600 \n",
      "class floor          weight: 0.167, IoU: 0.819 \n",
      "class wall           weight: 0.150, IoU: 0.525 \n",
      "class beam           weight: 0.383, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.009 \n",
      "class window         weight: 0.000, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.486 \n",
      "class table          weight: 0.052, IoU: 0.411 \n",
      "class chair          weight: 0.045, IoU: 0.530 \n",
      "class sofa           weight: 0.020, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.182 \n",
      "class board          weight: 0.029, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.233 \n",
      "\n",
      "Eval mean loss: 1.491745\n",
      "Eval accuracy: 0.624739\n",
      "Best mIoU: 0.302337\n",
      "**** Epoch 7 (9/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [04:55<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.213050\n",
      "Training accuracy: 0.926544\n",
      "---- EPOCH 007 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [00:33<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.536129\n",
      "eval point avg class IoU: 0.306116\n",
      "eval point accuracy: 0.670046\n",
      "eval point avg class acc: 0.392800\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.156, IoU: 0.565 \n",
      "class floor          weight: 0.165, IoU: 0.854 \n",
      "class wall           weight: 0.149, IoU: 0.650 \n",
      "class beam           weight: 0.392, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.432 \n",
      "class table          weight: 0.053, IoU: 0.478 \n",
      "class chair          weight: 0.045, IoU: 0.571 \n",
      "class sofa           weight: 0.018, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.222 \n",
      "class board          weight: 0.021, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.209 \n",
      "\n",
      "Eval mean loss: 1.536129\n",
      "Eval accuracy: 0.670046\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_parallel/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.306116\n",
      "**** Epoch 8 (10/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [05:38<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.218467\n",
      "Training accuracy: 0.925883\n",
      "---- EPOCH 008 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:23<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.773197\n",
      "eval point avg class IoU: 0.280996\n",
      "eval point accuracy: 0.644131\n",
      "eval point avg class acc: 0.380648\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.154, IoU: 0.535 \n",
      "class floor          weight: 0.165, IoU: 0.819 \n",
      "class wall           weight: 0.150, IoU: 0.612 \n",
      "class beam           weight: 0.384, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.008 \n",
      "class window         weight: 0.000, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.558 \n",
      "class table          weight: 0.055, IoU: 0.303 \n",
      "class chair          weight: 0.046, IoU: 0.358 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.232 \n",
      "class board          weight: 0.027, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.229 \n",
      "\n",
      "Eval mean loss: 1.773197\n",
      "Eval accuracy: 0.644131\n",
      "Best mIoU: 0.306116\n",
      "**** Epoch 9 (11/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 73/460 [01:39<08:46,  1.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 372\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    371\u001b[0m     args \u001b[38;5;241m=\u001b[39m parse_args()\n\u001b[0;32m--> 372\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 264\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    261\u001b[0m points, target \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    262\u001b[0m points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m seg_pred, trans_feat \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m seg_pred \u001b[38;5;241m=\u001b[39m seg_pred\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, NUM_CLASSES)\n\u001b[1;32m    267\u001b[0m batch_label \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-1.13.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/p2/Pointnet_Pointnet2_pytorch/models/pointnet2_sem_seg_parallel.py:59\u001b[0m, in \u001b[0;36mget_model.forward\u001b[0;34m(self, xyz)\u001b[0m\n\u001b[1;32m     56\u001b[0m l0_points \u001b[38;5;241m=\u001b[39m xyz\n\u001b[1;32m     57\u001b[0m l0_xyz \u001b[38;5;241m=\u001b[39m xyz[:, :\u001b[38;5;241m3\u001b[39m, :]\n\u001b[0;32m---> 59\u001b[0m l1_xyz, l1_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa1\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml0_xyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml0_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m l2_xyz, l2_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa2(l1_xyz, l1_points)\n\u001b[1;32m     61\u001b[0m l3_xyz, l3_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa3(l2_xyz, l2_points)\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-1.13.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/p2/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py:261\u001b[0m, in \u001b[0;36mPointNetSetAbstraction.forward\u001b[0;34m(self, xyz, points)\u001b[0m\n\u001b[1;32m    259\u001b[0m     new_xyz, new_points \u001b[38;5;241m=\u001b[39m sample_and_group_all(xyz, points)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     new_xyz, new_points \u001b[38;5;241m=\u001b[39m \u001b[43msample_and_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# new_xyz: sampled points position data, [B, npoint, C]\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# new_points: sampled points data, [B, npoint, nsample, C+D]\u001b[39;00m\n\u001b[1;32m    264\u001b[0m new_points \u001b[38;5;241m=\u001b[39m new_points\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [B, C+D, nsample,npoint]\u001b[39;00m\n",
      "File \u001b[0;32m~/p2/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py:124\u001b[0m, in \u001b[0;36msample_and_group\u001b[0;34m(npoint, radius, nsample, xyz, points, returnfps)\u001b[0m\n\u001b[1;32m    122\u001b[0m B, N, C \u001b[38;5;241m=\u001b[39m xyz\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    123\u001b[0m S \u001b[38;5;241m=\u001b[39m npoint\n\u001b[0;32m--> 124\u001b[0m fps_idx \u001b[38;5;241m=\u001b[39m \u001b[43mfarthest_point_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpoint\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [B, npoint, C]\u001b[39;00m\n\u001b[1;32m    125\u001b[0m new_xyz \u001b[38;5;241m=\u001b[39m index_points(xyz, fps_idx)\n\u001b[1;32m    126\u001b[0m idx \u001b[38;5;241m=\u001b[39m query_ball_point(radius, nsample, xyz, new_xyz)\n",
      "File \u001b[0;32m~/p2/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py:80\u001b[0m, in \u001b[0;36mfarthest_point_sample\u001b[0;34m(xyz, npoint)\u001b[0m\n\u001b[1;32m     78\u001b[0m centroids[:, i] \u001b[38;5;241m=\u001b[39m farthest\n\u001b[1;32m     79\u001b[0m centroid \u001b[38;5;241m=\u001b[39m xyz[batch_indices, farthest, :]\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m mask \u001b[38;5;241m=\u001b[39m dist \u001b[38;5;241m<\u001b[39m distance\n\u001b[1;32m     82\u001b[0m distance[mask] \u001b[38;5;241m=\u001b[39m dist[mask]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import importlib\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(f\"{training_mean_loss[-1]},{training_accuracy[-1]},{eval_mean_loss[-1]},{eval_accuracy[-1]}\\n\")\n",
    "\n",
    "def plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir):\n",
    "    # Move tensors to CPU\n",
    "    training_mean_loss_cpu = [val.item() for val in training_mean_loss]\n",
    "    training_accuracy_cpu = [val.item() for val in training_accuracy]\n",
    "    eval_mean_loss_cpu = [val.item() for val in eval_mean_loss]\n",
    "    eval_accuracy_cpu = [val.item() for val in eval_accuracy]\n",
    "\n",
    "    # Plot training mean loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_mean_loss_cpu, label='Training Mean Loss', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.title('Training Mean Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/training_mean_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_accuracy_cpu, label='Training Accuracy', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/training_accuracy.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot evaluation mean loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_mean_loss_cpu, label='Evaluation Mean Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.title('Evaluation Mean Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/eval_mean_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot evaluation accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_accuracy_cpu, label='Evaluation Accuracy', color='purple')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Evaluation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/eval_accuracy.png')\n",
    "    plt.close()\n",
    "# Usage:\n",
    "# plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Import the necessary modules here\n",
    "from data_utils.S3DISDataLoader import S3DISDataset\n",
    "import provider\n",
    "\n",
    "# Adjusted BASE_DIR and ROOT_DIR setup\n",
    "BASE_DIR = os.getcwd()  # Use the current working directory\n",
    "ROOT_DIR = BASE_DIR\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'models'))\n",
    "\n",
    "# Your class and function definitions remain unchanged...\n",
    "classes = ['ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase',\n",
    "           'board', 'clutter']\n",
    "class2label = {cls: i for i, cls in enumerate(classes)}\n",
    "seg_classes = class2label\n",
    "seg_label_to_cat = {}\n",
    "for i, cat in enumerate(seg_classes.keys()):\n",
    "    seg_label_to_cat[i] = cat\n",
    "\n",
    "def inplace_relu(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('ReLU') != -1:\n",
    "        m.inplace=True\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments or set default values if running in a Jupyter notebook/IPython.\"\"\"\n",
    "    if sys.argv[0].endswith('ipykernel_launcher.py') or 'ipykernel' in sys.argv[0]:\n",
    "        # Directly define args for Jupyter/Colab notebooks or IPython\n",
    "        class Args:\n",
    "            model = 'pointnet2_sem_seg_parallel'\n",
    "            batch_size = 16\n",
    "            epoch = 32\n",
    "            learning_rate = 0.001\n",
    "            gpu = '0'\n",
    "            optimizer = 'Adam'\n",
    "            log_dir = 'pointnet2_sem_seg_parallel'\n",
    "            decay_rate = 1e-4\n",
    "            npoint = 4096\n",
    "            step_size = 10\n",
    "            lr_decay = 0.7\n",
    "            test_area = 2\n",
    "        return Args()\n",
    "    else:\n",
    "        # Original argparse code for command-line execution\n",
    "        parser = argparse.ArgumentParser('Model')\n",
    "        parser.add_argument('--model', type=str, default='pointnet_sem_seg', help='model name [default: pointnet_sem_seg]')\n",
    "        parser.add_argument('--batch_size', type=int, default=16, help='Batch Size during training [default: 16]')\n",
    "        # Add the rest of your arguments here\n",
    "        return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    def log_string(str):\n",
    "        logger.info(str)\n",
    "        print(str)\n",
    "\n",
    "    '''HYPER PARAMETER'''\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    '''CREATE DIR'''\n",
    "    timestr = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
    "    experiment_dir = Path('./log/')\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    experiment_dir = experiment_dir.joinpath('sem_seg')\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    if args.log_dir is None:\n",
    "        experiment_dir = experiment_dir.joinpath(timestr)\n",
    "    else:\n",
    "        experiment_dir = experiment_dir.joinpath(args.log_dir)\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    checkpoints_dir = experiment_dir.joinpath('checkpoints/')\n",
    "    checkpoints_dir.mkdir(exist_ok=True)\n",
    "    log_dir = experiment_dir.joinpath('logs/')\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    '''LOG'''\n",
    "    args = parse_args()\n",
    "    logger = logging.getLogger(\"Model\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler = logging.FileHandler('%s/%s.txt' % (log_dir, args.model))\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    log_string('PARAMETER ...')\n",
    "    log_string(args)\n",
    "\n",
    "    root = '/home/puoza/p2/Pointnet_Pointnet2_pytorch/new'\n",
    "    NUM_CLASSES = 13\n",
    "    NUM_POINT = args.npoint\n",
    "    BATCH_SIZE = args.batch_size\n",
    "\n",
    "    print(\"start loading training data ...\")\n",
    "    TRAIN_DATASET = S3DISDataset(split='train', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "    print(\"start loading test data ...\")\n",
    "    TEST_DATASET = S3DISDataset(split='test', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "\n",
    "    trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=10,\n",
    "                                                  pin_memory=True, drop_last=True,\n",
    "                                                  worker_init_fn=lambda x: np.random.seed(x + int(time.time())))\n",
    "    testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=BATCH_SIZE, shuffle=False, num_workers=10,\n",
    "                                                 pin_memory=True, drop_last=True)\n",
    "    weights = torch.Tensor(TRAIN_DATASET.labelweights).cuda()\n",
    "\n",
    "    log_string(\"The number of training data is: %d\" % len(TRAIN_DATASET))\n",
    "    log_string(\"The number of test data is: %d\" % len(TEST_DATASET))\n",
    "\n",
    "    '''MODEL LOADING'''\n",
    "    MODEL = importlib.import_module(args.model)\n",
    "    shutil.copy('models/%s.py' % args.model, str(experiment_dir))\n",
    "    shutil.copy('models/pointnet2_utils.py', str(experiment_dir))\n",
    "\n",
    "    classifier = MODEL.get_model(NUM_CLASSES).cuda()\n",
    "    criterion = MODEL.get_loss().cuda()\n",
    "    classifier.apply(inplace_relu)\n",
    "\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv2d') != -1:\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(str(experiment_dir) + '/checkpoints/best_model.pth')\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "        log_string('Use pretrain model')\n",
    "    except:\n",
    "        log_string('No existing model, starting training from scratch...')\n",
    "        start_epoch = 0\n",
    "        classifier = classifier.apply(weights_init)\n",
    "\n",
    "    if args.optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(\n",
    "            classifier.parameters(),\n",
    "            lr=args.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=args.decay_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(classifier.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "\n",
    "    def bn_momentum_adjust(m, momentum):\n",
    "        if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
    "            m.momentum = momentum\n",
    "\n",
    "    LEARNING_RATE_CLIP = 1e-5\n",
    "    MOMENTUM_ORIGINAL = 0.1\n",
    "    MOMENTUM_DECCAY = 0.5\n",
    "    MOMENTUM_DECCAY_STEP = args.step_size\n",
    "\n",
    "    global_epoch = 0\n",
    "    best_iou = 0\n",
    "\n",
    "    for epoch in range(start_epoch, args.epoch):\n",
    "        '''Train on chopped scenes'''\n",
    "        log_string('**** Epoch %d (%d/%s) ****' % (global_epoch + 1, epoch + 1, args.epoch))\n",
    "        lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.step_size)), LEARNING_RATE_CLIP)\n",
    "        log_string('Learning rate:%f' % lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
    "        if momentum < 0.01:\n",
    "            momentum = 0.01\n",
    "        print('BN momentum updated to: %f' % momentum)\n",
    "        classifier = classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
    "        num_batches = len(trainDataLoader)\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        loss_sum = 0\n",
    "        classifier = classifier.train()\n",
    "\n",
    "        for i, (points, target) in tqdm(enumerate(trainDataLoader), total=len(trainDataLoader), smoothing=0.9):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            points = points.data.numpy()\n",
    "            points[:, :, :3] = provider.rotate_point_cloud_z(points[:, :, :3])\n",
    "            points = torch.Tensor(points)\n",
    "            points, target = points.float().cuda(), target.long().cuda()\n",
    "            points = points.transpose(2, 1)\n",
    "\n",
    "            seg_pred, trans_feat = classifier(points)\n",
    "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "            batch_label = target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
    "            target = target.view(-1, 1)[:, 0]\n",
    "            loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
    "            correct = np.sum(pred_choice == batch_label)\n",
    "            total_correct += correct\n",
    "            total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "            loss_sum += loss\n",
    "        log_string('Training mean loss: %f' % (loss_sum / num_batches))\n",
    "        log_string('Training accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            logger.info('Save model...')\n",
    "            savepath = str(checkpoints_dir) + '/model.pth'\n",
    "            log_string('Saving at %s' % savepath)\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, savepath)\n",
    "            log_string('Saving model....')\n",
    "\n",
    "        '''Evaluate on chopped scenes'''\n",
    "        with torch.no_grad():\n",
    "            num_batches = len(testDataLoader)\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            labelweights = np.zeros(NUM_CLASSES)\n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_iou_deno_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            classifier = classifier.eval()\n",
    "\n",
    "            log_string('---- EPOCH %03d EVALUATION ----' % (global_epoch + 1))\n",
    "            for i, (points, target) in tqdm(enumerate(testDataLoader), total=len(testDataLoader), smoothing=0.9):\n",
    "                points = points.data.numpy()\n",
    "                points = torch.Tensor(points)\n",
    "                points, target = points.float().cuda(), target.long().cuda()\n",
    "                points = points.transpose(2, 1)\n",
    "\n",
    "                seg_pred, trans_feat = classifier(points)\n",
    "                pred_val = seg_pred.contiguous().cpu().data.numpy()\n",
    "                seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "                batch_label = target.cpu().data.numpy()\n",
    "                target = target.view(-1, 1)[:, 0]\n",
    "                loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "                loss_sum += loss\n",
    "                pred_val = np.argmax(pred_val, 2)\n",
    "                correct = np.sum((pred_val == batch_label))\n",
    "                total_correct += correct\n",
    "                total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "                tmp, _ = np.histogram(batch_label, range(NUM_CLASSES + 1))\n",
    "                labelweights += tmp\n",
    "\n",
    "                for l in range(NUM_CLASSES):\n",
    "                    total_seen_class[l] += np.sum((batch_label == l))\n",
    "                    total_correct_class[l] += np.sum((pred_val == l) & (batch_label == l))\n",
    "                    total_iou_deno_class[l] += np.sum(((pred_val == l) | (batch_label == l)))\n",
    "\n",
    "            labelweights = labelweights.astype(float) / np.sum(labelweights.astype(float))\n",
    "            mIoU = np.mean(np.array(total_correct_class) / (np.array(total_iou_deno_class, dtype=float) + 1e-6))\n",
    "            log_string('eval mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "            log_string('eval point avg class IoU: %f' % (mIoU))\n",
    "            log_string('eval point accuracy: %f' % (total_correct / float(total_seen)))\n",
    "            log_string('eval point avg class acc: %f' % (\n",
    "                np.mean(np.array(total_correct_class) / (np.array(total_seen_class, dtype=float) + 1e-6))))\n",
    "\n",
    "            iou_per_class_str = '------- IoU --------\\n'\n",
    "            for l in range(NUM_CLASSES):\n",
    "                iou_per_class_str += 'class %s weight: %.3f, IoU: %.3f \\n' % (\n",
    "                    seg_label_to_cat[l] + ' ' * (14 - len(seg_label_to_cat[l])), labelweights[l - 1],\n",
    "                    total_correct_class[l] / float(total_iou_deno_class[l]))\n",
    "\n",
    "            log_string(iou_per_class_str)\n",
    "            log_string('Eval mean loss: %f' % (loss_sum / num_batches))\n",
    "            log_string('Eval accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "            if mIoU >= best_iou:\n",
    "                best_iou = mIoU\n",
    "                logger.info('Save model...')\n",
    "                savepath = str(checkpoints_dir) + '/best_model.pth'\n",
    "                log_string('Saving at %s' % savepath)\n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'class_avg_iou': mIoU,\n",
    "                    'model_state_dict': classifier.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }\n",
    "                torch.save(state, savepath)\n",
    "                log_string('Saving model....')\n",
    "            log_string('Best mIoU: %f' % best_iou)\n",
    "        global_epoch += 1\n",
    "        #plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "        #save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    args = parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426a1de-bec5-44a8-8370-1e4f657670fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.13.1",
   "language": "python",
   "name": "pytorch-gpu-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
