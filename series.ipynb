{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d5509d-d37e-49b1-9746-2337128fd314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "<__main__.parse_args.<locals>.Args object at 0x1555500c0df0>\n",
      "start loading training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0872371 1.1862054 1.        1.7367345 2.126663  2.0220127 1.788688\n",
      " 1.8918622 2.0941825 4.048591  1.7390136 2.4426463 1.2522498]\n",
      "Totally 7363 samples in train set.\n",
      "start loading test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.98it/s]\n",
      "/home/puoza/p2/Pointnet_Pointnet2_pytorch/data_utils/S3DISDataLoader.py:38: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.labelweights = np.power(np.amax(labelweights) / labelweights, 1 / 3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3699402 1.4154122 1.              inf 7.784936        inf 1.9372996\n",
      " 2.1385393 2.7646968       inf 2.5357857       inf 1.3914901]\n",
      "Totally 1180 samples in test set.\n",
      "The number of training data is: 7363\n",
      "The number of test data is: 1180\n",
      "Use pretrain model\n",
      "**** Epoch 1 (1/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [09:00<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.645505\n",
      "Training accuracy: 0.800722\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/model.pth\n",
      "Saving model....\n",
      "---- EPOCH 001 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:58<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.310730\n",
      "eval point avg class IoU: 0.277730\n",
      "eval point accuracy: 0.624442\n",
      "eval point avg class acc: 0.377117\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.158, IoU: 0.616 \n",
      "class floor          weight: 0.165, IoU: 0.828 \n",
      "class wall           weight: 0.148, IoU: 0.539 \n",
      "class beam           weight: 0.379, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.009 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.352 \n",
      "class table          weight: 0.063, IoU: 0.551 \n",
      "class chair          weight: 0.042, IoU: 0.271 \n",
      "class sofa           weight: 0.017, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.140 \n",
      "class board          weight: 0.028, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.304 \n",
      "\n",
      "Eval mean loss: 1.310730\n",
      "Eval accuracy: 0.624442\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.277730\n",
      "**** Epoch 2 (2/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [09:05<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.490414\n",
      "Training accuracy: 0.841323\n",
      "---- EPOCH 002 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:01<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.319047\n",
      "eval point avg class IoU: 0.284635\n",
      "eval point accuracy: 0.628874\n",
      "eval point avg class acc: 0.386914\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.151, IoU: 0.575 \n",
      "class floor          weight: 0.160, IoU: 0.829 \n",
      "class wall           weight: 0.144, IoU: 0.548 \n",
      "class beam           weight: 0.401, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.002 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.530 \n",
      "class table          weight: 0.060, IoU: 0.416 \n",
      "class chair          weight: 0.040, IoU: 0.372 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.134 \n",
      "class board          weight: 0.023, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.295 \n",
      "\n",
      "Eval mean loss: 1.319047\n",
      "Eval accuracy: 0.628874\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.284635\n",
      "**** Epoch 3 (3/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [08:57<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.415414\n",
      "Training accuracy: 0.862576\n",
      "---- EPOCH 003 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.224624\n",
      "eval point avg class IoU: 0.295796\n",
      "eval point accuracy: 0.632532\n",
      "eval point avg class acc: 0.387543\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.161, IoU: 0.604 \n",
      "class floor          weight: 0.164, IoU: 0.858 \n",
      "class wall           weight: 0.145, IoU: 0.541 \n",
      "class beam           weight: 0.383, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.524 \n",
      "class table          weight: 0.052, IoU: 0.465 \n",
      "class chair          weight: 0.046, IoU: 0.405 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.151 \n",
      "class board          weight: 0.028, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.298 \n",
      "\n",
      "Eval mean loss: 1.224624\n",
      "Eval accuracy: 0.632532\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.295796\n",
      "**** Epoch 4 (4/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [08:53<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.353769\n",
      "Training accuracy: 0.881252\n",
      "---- EPOCH 004 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:10<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.318036\n",
      "eval point avg class IoU: 0.290115\n",
      "eval point accuracy: 0.653628\n",
      "eval point avg class acc: 0.377938\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.152, IoU: 0.525 \n",
      "class floor          weight: 0.164, IoU: 0.810 \n",
      "class wall           weight: 0.148, IoU: 0.614 \n",
      "class beam           weight: 0.391, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.509 \n",
      "class table          weight: 0.055, IoU: 0.426 \n",
      "class chair          weight: 0.046, IoU: 0.452 \n",
      "class sofa           weight: 0.021, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.129 \n",
      "class board          weight: 0.022, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.307 \n",
      "\n",
      "Eval mean loss: 1.318036\n",
      "Eval accuracy: 0.653628\n",
      "Best mIoU: 0.295796\n",
      "**** Epoch 5 (5/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:51<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.315538\n",
      "Training accuracy: 0.893739\n",
      "---- EPOCH 005 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:11<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.248215\n",
      "eval point avg class IoU: 0.306386\n",
      "eval point accuracy: 0.673044\n",
      "eval point avg class acc: 0.370653\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.150, IoU: 0.607 \n",
      "class floor          weight: 0.170, IoU: 0.851 \n",
      "class wall           weight: 0.156, IoU: 0.632 \n",
      "class beam           weight: 0.365, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.575 \n",
      "class table          weight: 0.062, IoU: 0.464 \n",
      "class chair          weight: 0.049, IoU: 0.411 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.139 \n",
      "class board          weight: 0.025, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.304 \n",
      "\n",
      "Eval mean loss: 1.248215\n",
      "Eval accuracy: 0.673044\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.306386\n",
      "**** Epoch 6 (6/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [08:48<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.273859\n",
      "Training accuracy: 0.906360\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/model.pth\n",
      "Saving model....\n",
      "---- EPOCH 006 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:11<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.191329\n",
      "eval point avg class IoU: 0.303734\n",
      "eval point accuracy: 0.689435\n",
      "eval point avg class acc: 0.404664\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.152, IoU: 0.597 \n",
      "class floor          weight: 0.166, IoU: 0.826 \n",
      "class wall           weight: 0.147, IoU: 0.668 \n",
      "class beam           weight: 0.388, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.526 \n",
      "class table          weight: 0.054, IoU: 0.516 \n",
      "class chair          weight: 0.044, IoU: 0.305 \n",
      "class sofa           weight: 0.018, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.205 \n",
      "class board          weight: 0.030, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.305 \n",
      "\n",
      "Eval mean loss: 1.191329\n",
      "Eval accuracy: 0.689435\n",
      "Best mIoU: 0.306386\n",
      "**** Epoch 7 (7/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:47<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.262533\n",
      "Training accuracy: 0.908718\n",
      "---- EPOCH 007 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:11<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.240333\n",
      "eval point avg class IoU: 0.298609\n",
      "eval point accuracy: 0.679529\n",
      "eval point avg class acc: 0.381458\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.153, IoU: 0.586 \n",
      "class floor          weight: 0.165, IoU: 0.849 \n",
      "class wall           weight: 0.150, IoU: 0.634 \n",
      "class beam           weight: 0.386, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.554 \n",
      "class table          weight: 0.058, IoU: 0.375 \n",
      "class chair          weight: 0.046, IoU: 0.385 \n",
      "class sofa           weight: 0.020, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.129 \n",
      "class board          weight: 0.021, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.369 \n",
      "\n",
      "Eval mean loss: 1.240333\n",
      "Eval accuracy: 0.679529\n",
      "Best mIoU: 0.306386\n",
      "**** Epoch 8 (8/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:49<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.245044\n",
      "Training accuracy: 0.915916\n",
      "---- EPOCH 008 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:11<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.152464\n",
      "eval point avg class IoU: 0.299472\n",
      "eval point accuracy: 0.706707\n",
      "eval point avg class acc: 0.375885\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.153, IoU: 0.636 \n",
      "class floor          weight: 0.165, IoU: 0.840 \n",
      "class wall           weight: 0.144, IoU: 0.694 \n",
      "class beam           weight: 0.393, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.514 \n",
      "class table          weight: 0.060, IoU: 0.407 \n",
      "class chair          weight: 0.043, IoU: 0.345 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.140 \n",
      "class board          weight: 0.024, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.318 \n",
      "\n",
      "Eval mean loss: 1.152464\n",
      "Eval accuracy: 0.706707\n",
      "Best mIoU: 0.306386\n",
      "**** Epoch 9 (9/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:48<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.233146\n",
      "Training accuracy: 0.920011\n",
      "---- EPOCH 009 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:10<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.253340\n",
      "eval point avg class IoU: 0.300846\n",
      "eval point accuracy: 0.659348\n",
      "eval point avg class acc: 0.384628\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.151, IoU: 0.619 \n",
      "class floor          weight: 0.163, IoU: 0.838 \n",
      "class wall           weight: 0.145, IoU: 0.593 \n",
      "class beam           weight: 0.388, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.534 \n",
      "class table          weight: 0.061, IoU: 0.476 \n",
      "class chair          weight: 0.045, IoU: 0.339 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.187 \n",
      "class board          weight: 0.028, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.325 \n",
      "\n",
      "Eval mean loss: 1.253340\n",
      "Eval accuracy: 0.659348\n",
      "Best mIoU: 0.306386\n",
      "**** Epoch 10 (10/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:50<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.218170\n",
      "Training accuracy: 0.923905\n",
      "---- EPOCH 010 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:10<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.226258\n",
      "eval point avg class IoU: 0.310181\n",
      "eval point accuracy: 0.670433\n",
      "eval point avg class acc: 0.387361\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.164, IoU: 0.571 \n",
      "class floor          weight: 0.169, IoU: 0.831 \n",
      "class wall           weight: 0.149, IoU: 0.638 \n",
      "class beam           weight: 0.370, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.000, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.613 \n",
      "class table          weight: 0.059, IoU: 0.471 \n",
      "class chair          weight: 0.045, IoU: 0.411 \n",
      "class sofa           weight: 0.022, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.143 \n",
      "class board          weight: 0.021, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.354 \n",
      "\n",
      "Eval mean loss: 1.226258\n",
      "Eval accuracy: 0.670433\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 11 (11/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:48<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.175301\n",
      "Training accuracy: 0.937884\n",
      "Saving at log/sem_seg/pointnet2_sem_seg_series/checkpoints/model.pth\n",
      "Saving model....\n",
      "---- EPOCH 011 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:11<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.469277\n",
      "eval point avg class IoU: 0.285889\n",
      "eval point accuracy: 0.635548\n",
      "eval point avg class acc: 0.361007\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.156, IoU: 0.573 \n",
      "class floor          weight: 0.167, IoU: 0.839 \n",
      "class wall           weight: 0.145, IoU: 0.587 \n",
      "class beam           weight: 0.389, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.002, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.526 \n",
      "class table          weight: 0.054, IoU: 0.394 \n",
      "class chair          weight: 0.047, IoU: 0.330 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.144 \n",
      "class board          weight: 0.022, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.323 \n",
      "\n",
      "Eval mean loss: 1.469277\n",
      "Eval accuracy: 0.635548\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 12 (12/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:47<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.166626\n",
      "Training accuracy: 0.940816\n",
      "---- EPOCH 012 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:09<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.305377\n",
      "eval point avg class IoU: 0.303311\n",
      "eval point accuracy: 0.708117\n",
      "eval point avg class acc: 0.370204\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.157, IoU: 0.600 \n",
      "class floor          weight: 0.167, IoU: 0.845 \n",
      "class wall           weight: 0.149, IoU: 0.711 \n",
      "class beam           weight: 0.377, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.000, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.531 \n",
      "class table          weight: 0.054, IoU: 0.378 \n",
      "class chair          weight: 0.044, IoU: 0.296 \n",
      "class sofa           weight: 0.021, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.231 \n",
      "class board          weight: 0.030, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.351 \n",
      "\n",
      "Eval mean loss: 1.305377\n",
      "Eval accuracy: 0.708117\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 13 (13/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:43<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.171069\n",
      "Training accuracy: 0.939854\n",
      "---- EPOCH 013 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:10<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.221177\n",
      "eval point avg class IoU: 0.309431\n",
      "eval point accuracy: 0.708773\n",
      "eval point avg class acc: 0.379205\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.148, IoU: 0.604 \n",
      "class floor          weight: 0.166, IoU: 0.852 \n",
      "class wall           weight: 0.146, IoU: 0.681 \n",
      "class beam           weight: 0.387, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.598 \n",
      "class table          weight: 0.062, IoU: 0.379 \n",
      "class chair          weight: 0.045, IoU: 0.330 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.191 \n",
      "class board          weight: 0.026, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.388 \n",
      "\n",
      "Eval mean loss: 1.221177\n",
      "Eval accuracy: 0.708773\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 14 (14/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:42<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.156008\n",
      "Training accuracy: 0.944498\n",
      "---- EPOCH 014 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:11<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.364447\n",
      "eval point avg class IoU: 0.296216\n",
      "eval point accuracy: 0.672523\n",
      "eval point avg class acc: 0.370041\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.156, IoU: 0.651 \n",
      "class floor          weight: 0.165, IoU: 0.841 \n",
      "class wall           weight: 0.148, IoU: 0.620 \n",
      "class beam           weight: 0.381, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.518 \n",
      "class table          weight: 0.058, IoU: 0.418 \n",
      "class chair          weight: 0.043, IoU: 0.363 \n",
      "class sofa           weight: 0.024, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.117 \n",
      "class board          weight: 0.024, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.322 \n",
      "\n",
      "Eval mean loss: 1.364447\n",
      "Eval accuracy: 0.672523\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 15 (15/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 460/460 [08:46<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean loss: 0.164484\n",
      "Training accuracy: 0.941635\n",
      "---- EPOCH 015 EVALUATION ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73/73 [01:10<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mean loss: 1.605323\n",
      "eval point avg class IoU: 0.269323\n",
      "eval point accuracy: 0.623550\n",
      "eval point avg class acc: 0.359873\n",
      "------- IoU --------\n",
      "class ceiling        weight: 0.163, IoU: 0.578 \n",
      "class floor          weight: 0.166, IoU: 0.843 \n",
      "class wall           weight: 0.144, IoU: 0.566 \n",
      "class beam           weight: 0.382, IoU: 0.000 \n",
      "class column         weight: 0.000, IoU: 0.000 \n",
      "class window         weight: 0.001, IoU: 0.000 \n",
      "class door           weight: 0.000, IoU: 0.468 \n",
      "class table          weight: 0.059, IoU: 0.329 \n",
      "class chair          weight: 0.045, IoU: 0.241 \n",
      "class sofa           weight: 0.019, IoU: 0.000 \n",
      "class bookcase       weight: 0.000, IoU: 0.157 \n",
      "class board          weight: 0.023, IoU: 0.000 \n",
      "class clutter        weight: 0.000, IoU: 0.319 \n",
      "\n",
      "Eval mean loss: 1.605323\n",
      "Eval accuracy: 0.623550\n",
      "Best mIoU: 0.310181\n",
      "**** Epoch 16 (16/32) ****\n",
      "Learning rate:0.000700\n",
      "BN momentum updated to: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/460 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 372\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    371\u001b[0m     args \u001b[38;5;241m=\u001b[39m parse_args()\n\u001b[0;32m--> 372\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 255\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    252\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    253\u001b[0m classifier \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (points, target) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(trainDataLoader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainDataLoader), smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m):\n\u001b[1;32m    256\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    258\u001b[0m     points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import importlib\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(f\"{training_mean_loss[-1]},{training_accuracy[-1]},{eval_mean_loss[-1]},{eval_accuracy[-1]}\\n\")\n",
    "\n",
    "def plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir):\n",
    "    # Move tensors to CPU\n",
    "    training_mean_loss_cpu = [val.item() for val in training_mean_loss]\n",
    "    training_accuracy_cpu = [val.item() for val in training_accuracy]\n",
    "    eval_mean_loss_cpu = [val.item() for val in eval_mean_loss]\n",
    "    eval_accuracy_cpu = [val.item() for val in eval_accuracy]\n",
    "\n",
    "    # Plot training mean loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_mean_loss_cpu, label='Training Mean Loss', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.title('Training Mean Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/training_mean_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_accuracy_cpu, label='Training Accuracy', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/training_accuracy.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot evaluation mean loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_mean_loss_cpu, label='Evaluation Mean Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.title('Evaluation Mean Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/eval_mean_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot evaluation accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_accuracy_cpu, label='Evaluation Accuracy', color='purple')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Evaluation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(str(experiment_dir) + '/eval_accuracy.png')\n",
    "    plt.close()\n",
    "# Usage:\n",
    "# plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Import the necessary modules here\n",
    "from data_utils.S3DISDataLoader import S3DISDataset\n",
    "import provider\n",
    "\n",
    "# Adjusted BASE_DIR and ROOT_DIR setup\n",
    "BASE_DIR = os.getcwd()  # Use the current working directory\n",
    "ROOT_DIR = BASE_DIR\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'models'))\n",
    "\n",
    "# Your class and function definitions remain unchanged...\n",
    "classes = ['ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase',\n",
    "           'board', 'clutter']\n",
    "class2label = {cls: i for i, cls in enumerate(classes)}\n",
    "seg_classes = class2label\n",
    "seg_label_to_cat = {}\n",
    "for i, cat in enumerate(seg_classes.keys()):\n",
    "    seg_label_to_cat[i] = cat\n",
    "\n",
    "def inplace_relu(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('ReLU') != -1:\n",
    "        m.inplace=True\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments or set default values if running in a Jupyter notebook/IPython.\"\"\"\n",
    "    if sys.argv[0].endswith('ipykernel_launcher.py') or 'ipykernel' in sys.argv[0]:\n",
    "        # Directly define args for Jupyter/Colab notebooks or IPython\n",
    "        class Args:\n",
    "            model = 'pointnet2_sem_seg_series'\n",
    "            batch_size = 16\n",
    "            epoch = 32\n",
    "            learning_rate = 0.001\n",
    "            gpu = '0'\n",
    "            optimizer = 'Adam'\n",
    "            log_dir = 'pointnet2_sem_seg_series'\n",
    "            decay_rate = 1e-4\n",
    "            npoint = 4096\n",
    "            step_size = 10\n",
    "            lr_decay = 0.7\n",
    "            test_area = 2\n",
    "        return Args()\n",
    "    else:\n",
    "        # Original argparse code for command-line execution\n",
    "        parser = argparse.ArgumentParser('Model')\n",
    "        parser.add_argument('--model', type=str, default='pointnet_sem_seg', help='model name [default: pointnet_sem_seg]')\n",
    "        parser.add_argument('--batch_size', type=int, default=16, help='Batch Size during training [default: 16]')\n",
    "        # Add the rest of your arguments here\n",
    "        return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    def log_string(str):\n",
    "        logger.info(str)\n",
    "        print(str)\n",
    "\n",
    "    '''HYPER PARAMETER'''\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    '''CREATE DIR'''\n",
    "    timestr = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
    "    experiment_dir = Path('./log/')\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    experiment_dir = experiment_dir.joinpath('sem_seg')\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    if args.log_dir is None:\n",
    "        experiment_dir = experiment_dir.joinpath(timestr)\n",
    "    else:\n",
    "        experiment_dir = experiment_dir.joinpath(args.log_dir)\n",
    "    experiment_dir.mkdir(exist_ok=True)\n",
    "    checkpoints_dir = experiment_dir.joinpath('checkpoints/')\n",
    "    checkpoints_dir.mkdir(exist_ok=True)\n",
    "    log_dir = experiment_dir.joinpath('logs/')\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    '''LOG'''\n",
    "    args = parse_args()\n",
    "    logger = logging.getLogger(\"Model\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler = logging.FileHandler('%s/%s.txt' % (log_dir, args.model))\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    log_string('PARAMETER ...')\n",
    "    log_string(args)\n",
    "\n",
    "    root = '/home/puoza/p2/Pointnet_Pointnet2_pytorch/new'\n",
    "    NUM_CLASSES = 13\n",
    "    NUM_POINT = args.npoint\n",
    "    BATCH_SIZE = args.batch_size\n",
    "\n",
    "    print(\"start loading training data ...\")\n",
    "    TRAIN_DATASET = S3DISDataset(split='train', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "    print(\"start loading test data ...\")\n",
    "    TEST_DATASET = S3DISDataset(split='test', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "\n",
    "    trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=10,\n",
    "                                                  pin_memory=True, drop_last=True,\n",
    "                                                  worker_init_fn=lambda x: np.random.seed(x + int(time.time())))\n",
    "    testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=BATCH_SIZE, shuffle=False, num_workers=10,\n",
    "                                                 pin_memory=True, drop_last=True)\n",
    "    weights = torch.Tensor(TRAIN_DATASET.labelweights).cuda()\n",
    "\n",
    "    log_string(\"The number of training data is: %d\" % len(TRAIN_DATASET))\n",
    "    log_string(\"The number of test data is: %d\" % len(TEST_DATASET))\n",
    "\n",
    "    '''MODEL LOADING'''\n",
    "    MODEL = importlib.import_module(args.model)\n",
    "    shutil.copy('models/%s.py' % args.model, str(experiment_dir))\n",
    "    shutil.copy('models/pointnet2_utils.py', str(experiment_dir))\n",
    "\n",
    "    classifier = MODEL.get_model(NUM_CLASSES).cuda()\n",
    "    criterion = MODEL.get_loss().cuda()\n",
    "    classifier.apply(inplace_relu)\n",
    "\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv2d') != -1:\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(str(experiment_dir) + '/checkpoints/best_model.pth')\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "        log_string('Use pretrain model')\n",
    "    except:\n",
    "        log_string('No existing model, starting training from scratch...')\n",
    "        start_epoch = 0\n",
    "        classifier = classifier.apply(weights_init)\n",
    "\n",
    "    if args.optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(\n",
    "            classifier.parameters(),\n",
    "            lr=args.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=args.decay_rate\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(classifier.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "\n",
    "    def bn_momentum_adjust(m, momentum):\n",
    "        if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
    "            m.momentum = momentum\n",
    "\n",
    "    LEARNING_RATE_CLIP = 1e-5\n",
    "    MOMENTUM_ORIGINAL = 0.1\n",
    "    MOMENTUM_DECCAY = 0.5\n",
    "    MOMENTUM_DECCAY_STEP = args.step_size\n",
    "\n",
    "    global_epoch = 0\n",
    "    best_iou = 0\n",
    "\n",
    "    for epoch in range(start_epoch, args.epoch):\n",
    "        '''Train on chopped scenes'''\n",
    "        log_string('**** Epoch %d (%d/%s) ****' % (global_epoch + 1, epoch + 1, args.epoch))\n",
    "        lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.step_size)), LEARNING_RATE_CLIP)\n",
    "        log_string('Learning rate:%f' % lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
    "        if momentum < 0.01:\n",
    "            momentum = 0.01\n",
    "        print('BN momentum updated to: %f' % momentum)\n",
    "        classifier = classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
    "        num_batches = len(trainDataLoader)\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        loss_sum = 0\n",
    "        classifier = classifier.train()\n",
    "\n",
    "        for i, (points, target) in tqdm(enumerate(trainDataLoader), total=len(trainDataLoader), smoothing=0.9):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            points = points.data.numpy()\n",
    "            points[:, :, :3] = provider.rotate_point_cloud_z(points[:, :, :3])\n",
    "            points = torch.Tensor(points)\n",
    "            points, target = points.float().cuda(), target.long().cuda()\n",
    "            points = points.transpose(2, 1)\n",
    "\n",
    "            seg_pred, trans_feat = classifier(points)\n",
    "            seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "            batch_label = target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
    "            target = target.view(-1, 1)[:, 0]\n",
    "            loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
    "            correct = np.sum(pred_choice == batch_label)\n",
    "            total_correct += correct\n",
    "            total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "            loss_sum += loss\n",
    "        log_string('Training mean loss: %f' % (loss_sum / num_batches))\n",
    "        log_string('Training accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            logger.info('Save model...')\n",
    "            savepath = str(checkpoints_dir) + '/model.pth'\n",
    "            log_string('Saving at %s' % savepath)\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, savepath)\n",
    "            log_string('Saving model....')\n",
    "\n",
    "        '''Evaluate on chopped scenes'''\n",
    "        with torch.no_grad():\n",
    "            num_batches = len(testDataLoader)\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            labelweights = np.zeros(NUM_CLASSES)\n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_iou_deno_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            classifier = classifier.eval()\n",
    "\n",
    "            log_string('---- EPOCH %03d EVALUATION ----' % (global_epoch + 1))\n",
    "            for i, (points, target) in tqdm(enumerate(testDataLoader), total=len(testDataLoader), smoothing=0.9):\n",
    "                points = points.data.numpy()\n",
    "                points = torch.Tensor(points)\n",
    "                points, target = points.float().cuda(), target.long().cuda()\n",
    "                points = points.transpose(2, 1)\n",
    "\n",
    "                seg_pred, trans_feat = classifier(points)\n",
    "                pred_val = seg_pred.contiguous().cpu().data.numpy()\n",
    "                seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "                batch_label = target.cpu().data.numpy()\n",
    "                target = target.view(-1, 1)[:, 0]\n",
    "                loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "                loss_sum += loss\n",
    "                pred_val = np.argmax(pred_val, 2)\n",
    "                correct = np.sum((pred_val == batch_label))\n",
    "                total_correct += correct\n",
    "                total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "                tmp, _ = np.histogram(batch_label, range(NUM_CLASSES + 1))\n",
    "                labelweights += tmp\n",
    "\n",
    "                for l in range(NUM_CLASSES):\n",
    "                    total_seen_class[l] += np.sum((batch_label == l))\n",
    "                    total_correct_class[l] += np.sum((pred_val == l) & (batch_label == l))\n",
    "                    total_iou_deno_class[l] += np.sum(((pred_val == l) | (batch_label == l)))\n",
    "\n",
    "            labelweights = labelweights.astype(float) / np.sum(labelweights.astype(float))\n",
    "            mIoU = np.mean(np.array(total_correct_class) / (np.array(total_iou_deno_class, dtype=float) + 1e-6))\n",
    "            log_string('eval mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "            log_string('eval point avg class IoU: %f' % (mIoU))\n",
    "            log_string('eval point accuracy: %f' % (total_correct / float(total_seen)))\n",
    "            log_string('eval point avg class acc: %f' % (\n",
    "                np.mean(np.array(total_correct_class) / (np.array(total_seen_class, dtype=float) + 1e-6))))\n",
    "\n",
    "            iou_per_class_str = '------- IoU --------\\n'\n",
    "            for l in range(NUM_CLASSES):\n",
    "                iou_per_class_str += 'class %s weight: %.3f, IoU: %.3f \\n' % (\n",
    "                    seg_label_to_cat[l] + ' ' * (14 - len(seg_label_to_cat[l])), labelweights[l - 1],\n",
    "                    total_correct_class[l] / float(total_iou_deno_class[l]))\n",
    "\n",
    "            log_string(iou_per_class_str)\n",
    "            log_string('Eval mean loss: %f' % (loss_sum / num_batches))\n",
    "            log_string('Eval accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "            if mIoU >= best_iou:\n",
    "                best_iou = mIoU\n",
    "                logger.info('Save model...')\n",
    "                savepath = str(checkpoints_dir) + '/best_model.pth'\n",
    "                log_string('Saving at %s' % savepath)\n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'class_avg_iou': mIoU,\n",
    "                    'model_state_dict': classifier.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }\n",
    "                torch.save(state, savepath)\n",
    "                log_string('Saving model....')\n",
    "            log_string('Best mIoU: %f' % best_iou)\n",
    "        global_epoch += 1\n",
    "        #plot_and_save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "        #save_metrics(training_mean_loss, training_accuracy, eval_mean_loss, eval_accuracy, experiment_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    args = parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2cedf-6dbe-404b-9c42-fc209ef99965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d586f7d-ca26-4c60-a90a-29a816dbe43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
