{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b185a15-205e-418f-b883-404ce53531ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.pointnet2_utils import PointNetSetAbstraction, PointNetFeaturePropagation\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from scipy.spatial.distance import directed_hausdorff  # Importing the directed_hausdorff function\n",
    "import torch.optim as optim\n",
    "import open3d as o3d\n",
    "import random  # Make sure to include this at the start of your script\n",
    "\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "\n",
    "# Define the classes\n",
    "classes = ['ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase',\n",
    "           'board', 'clutter']\n",
    "\n",
    "\n",
    "\n",
    "class TransformerFeatureAbstraction(nn.Module):\n",
    "    def __init__(self, feature_dim, num_heads):\n",
    "        super(TransformerFeatureAbstraction, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoderLayer(\n",
    "            d_model=feature_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=2048,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.positional_embeddings = nn.Parameter(torch.randn(1, 256, feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting x of shape [batch_size, num_points, feature_dim]\n",
    "        # Add positional encodings to the input features\n",
    "        x = x + self.positional_embeddings\n",
    "\n",
    "        return self.transformer(x)\n",
    "\n",
    "\n",
    "class Validator:\n",
    "    def __init__(self, validator_folder):\n",
    "        self.validator_folder = validator_folder\n",
    "        self.ground_truth_files = self.load_ground_truth_files()\n",
    "\n",
    "    \n",
    "    def preprocess_point_cloud(self, points):\n",
    "        \"\"\"\n",
    "        Preprocesses a point cloud by centering it around its centroid.\n",
    "\n",
    "        Args:\n",
    "        points (np.array): Array containing point cloud data\n",
    "\n",
    "        Returns:\n",
    "        o3d.geometry.PointCloud: Preprocessed point cloud object\n",
    "        \"\"\"\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        centroid = np.mean(np.asarray(pcd.points), axis=0)\n",
    "        pcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points) - centroid)\n",
    "        return pcd\n",
    "\n",
    "    def read_point_cloud(self, file_path):\n",
    "        \"\"\"\n",
    "        Read point cloud data from a .txt file.\n",
    "\n",
    "        Args:\n",
    "        file_path (str): Path to the .txt file\n",
    "\n",
    "        Returns:\n",
    "        np.array: Array containing point cloud data\n",
    "        \"\"\"\n",
    "        points = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                values = line.strip().split()\n",
    "                if len(values) >= 4:  # Assuming XYZRGB values are present\n",
    "                    point = [float(val) for val in values[:4]]  # Consider first 4 values\n",
    "                    points.append(point)\n",
    "        return np.array(points)\n",
    "\n",
    "    def calculate_hausdorff_distance(self, source_pcd, target_pcd):\n",
    "        source_points = np.asarray(source_pcd.points)\n",
    "        target_points = np.asarray(target_pcd.points)\n",
    "        return max(directed_hausdorff(source_points, target_points)[0],\n",
    "                   directed_hausdorff(target_points, source_points)[0])\n",
    "\n",
    "   \n",
    "    def calculate_emd(self, source_pcd, target_pcd):\n",
    "        source_points = np.asarray(source_pcd.points).flatten()\n",
    "        target_points = np.asarray(target_pcd.points).flatten()\n",
    "        return wasserstein_distance(source_points, target_points)\n",
    "\n",
    "    def calculate_rmse(self, source_pcd, target_pcd):\n",
    "        source_points = np.asarray(source_pcd.points)\n",
    "        target_points = np.asarray(target_pcd.points)\n",
    "        squared_errors = np.sum(np.square(source_points - target_points), axis=1)\n",
    "        return np.sqrt(np.mean(squared_errors))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def load_ground_truth_files(self):\n",
    "        ground_truth_files = {}\n",
    "        for class_id in range(1, 14):\n",
    "            file_path = os.path.join(self.validator_folder, f\"{class_id}.txt\")\n",
    "            print(\"Checking file path:\", file_path)  # Debug statement\n",
    "            if os.path.exists(file_path):\n",
    "                print(\"File exists:\", file_path)  # Debug statement\n",
    "                points = []\n",
    "                with open(file_path, 'r') as file:\n",
    "                    for line in file:\n",
    "                        values = line.strip().split()\n",
    "                        if len(values) >= 3:\n",
    "                            point = [float(val) for val in values[:3]]\n",
    "                            points.append(point)\n",
    "                ground_truth_files[class_id] = np.array(points)\n",
    "            else:\n",
    "                print(\"File does not exist:\", file_path)  # Debug statement\n",
    "        return ground_truth_files\n",
    "\n",
    "    def calculate_min_loss_class(self, validation_points):\n",
    "        min_loss_class = None\n",
    "        min_loss_value = float('inf')\n",
    "    \n",
    "        for class_id, ground_truth_points in self.ground_truth_files.items():\n",
    "            total_loss = 0\n",
    "            if len(validation_points) >= 100:  # Check if there are enough validation points\n",
    "                # Calculate loss using validation_points and the corresponding ground truth file\n",
    "                source_pcd = self.preprocess_point_cloud(np.array(validation_points)[:, :3])\n",
    "                target_pcd = self.preprocess_point_cloud(np.array(ground_truth_points)[:, :3])\n",
    "    \n",
    "                reg_result = o3d.pipelines.registration.registration_icp(\n",
    "                    source_pcd, target_pcd, 0.02, np.eye(4),\n",
    "                    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    \n",
    "                aligned_pcd = source_pcd.transform(reg_result.transformation)\n",
    "                emd_dist = self.calculate_emd(source_pcd, aligned_pcd)\n",
    "                rmse_dist = self.calculate_rmse(source_pcd, aligned_pcd)\n",
    "\n",
    "                hausdorff_dist = directed_hausdorff(np.array(validation_points)[:, :3], ground_truth_points[:, :3])[0]\n",
    "                total_loss -= hausdorff_dist  + emd_dist +rmse_dist\n",
    "            else:\n",
    "                total_loss += 0.001  # Add 10 to the total loss as a penalty for less than 100 validation points\n",
    "    \n",
    "            if total_loss < min_loss_value:\n",
    "                min_loss_value = total_loss\n",
    "                min_loss_class = class_id\n",
    "    \n",
    "        return min_loss_class, min_loss_value\n",
    "\n",
    "    def calculate_validation_loss(self, xyzc_data_chunk):\n",
    "    \n",
    "        total_loss = 0\n",
    "        min_loss_value=100\n",
    "        for chunk_id, xyzc_data in enumerate(xyzc_data_chunk):\n",
    "            current_class = None\n",
    "            validation_points = []\n",
    "    \n",
    "            for point in xyzc_data:\n",
    "                x, y, z, c = point\n",
    "    \n",
    "                if current_class is None:\n",
    "                    current_class = c\n",
    "                    validation_points.append(point)\n",
    "                elif c == current_class:\n",
    "                    prev_point = validation_points[-1]\n",
    "                    # Check if the x-distance between consecutive points is less than 2\n",
    "                    if abs(prev_point[0] - x) < 2:\n",
    "                        validation_points.append(point)\n",
    "                    else:\n",
    "                        if len(validation_points) >= 100:  # Check if there are enough validation points\n",
    "                            # Calculate loss using validation_points and the corresponding ground truth file\n",
    "                            ground_truth_points = self.ground_truth_files.get(current_class, [])\n",
    "                            if len(ground_truth_points) > 0:\n",
    "                                source_pcd = self.preprocess_point_cloud(np.array(validation_points)[:,:3])\n",
    "                                target_pcd = self.preprocess_point_cloud(np.array(ground_truth_points)[:,:3])\n",
    "    \n",
    "                                reg_result = o3d.pipelines.registration.registration_icp(\n",
    "                                    source_pcd, target_pcd, 0.02, np.eye(4),\n",
    "                                    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                                    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "                                min_loss_class,min_loss_value= self.calculate_min_loss_class(np.array(validation_points)[:,:3])\n",
    "                                aligned_pcd = source_pcd.transform(reg_result.transformation)\n",
    "                                emd_dist = self.calculate_emd(source_pcd, aligned_pcd)\n",
    "                                rmse_dist = self.calculate_rmse(source_pcd, aligned_pcd)\n",
    "\n",
    "                                hausdorff_dist = directed_hausdorff(np.array(validation_points)[:, :3], ground_truth_points[:, :3])[0]\n",
    "                                total_loss = hausdorff_dist  +emd_dist +rmse_dist\n",
    "                        else:\n",
    "                            total_loss += 0.001 # Add 10 to the total loss as a penalty for less than 100 validation points\n",
    "                        # Reset validation_points\n",
    "                        validation_points = [point]\n",
    "                else:\n",
    "                    if len(validation_points) >= 100:  # Check if there are enough validation points\n",
    "                        # Calculate loss using validation_points and the corresponding ground truth file\n",
    "                        ground_truth_points = self.ground_truth_files.get(current_class, [])\n",
    "                        if len(ground_truth_points) > 0:\n",
    "                            source_pcd = self.preprocess_point_cloud(np.array(validation_points)[:,:3])\n",
    "                            target_pcd = self.preprocess_point_cloud(np.array(ground_truth_points)[:,:3])\n",
    "    \n",
    "                            reg_result = o3d.pipelines.registration.registration_icp(\n",
    "                                source_pcd, target_pcd, 0.02, np.eye(4),\n",
    "                                o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                                o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "                            min_loss_class,min_loss_value= self.calculate_min_loss_class(np.array(validation_points)[:,:3])\n",
    "                            aligned_pcd = source_pcd.transform(reg_result.transformation)\n",
    "                            emd_dist = self.calculate_emd(source_pcd, aligned_pcd)\n",
    "                            rmse_dist = self.calculate_rmse(source_pcd, aligned_pcd)\n",
    "                            hausdorff_dist = directed_hausdorff(np.array(validation_points)[:, :3], ground_truth_points[:, :3])[0]\n",
    "                            total_loss = hausdorff_dist +emd_dist+ rmse_dist\n",
    "                    else:\n",
    "                        total_loss += 0.001  # Add 10 to the total loss as a penalty for less than 100 validation points\n",
    "                    # Reset current_class and validation_points\n",
    "                    current_class = c\n",
    "                    validation_points = [point]\n",
    "    \n",
    "            # After the loop, calculate loss for the last set of validation_points\n",
    "            if len(validation_points) >= 100:  # Check if there are enough validation points\n",
    "                # Calculate loss using validation_points and the corresponding ground truth file\n",
    "                ground_truth_points = self.ground_truth_files.get(current_class, [])\n",
    "                if len(ground_truth_points) > 0:\n",
    "                    source_pcd = self.preprocess_point_cloud(np.array(validation_points)[:,:3])\n",
    "                    target_pcd = self.preprocess_point_cloud(np.array(ground_truth_points)[:,:3])\n",
    "    \n",
    "                    reg_result = o3d.pipelines.registration.registration_icp(\n",
    "                        source_pcd, target_pcd, 0.02, np.eye(4),\n",
    "                        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "                    min_loss_class,min_loss_value= self.calculate_min_loss_class(np.array(validation_points)[:,:3])\n",
    "                    aligned_pcd = source_pcd.transform(reg_result.transformation)\n",
    "                    emd_dist = self.calculate_emd(source_pcd, aligned_pcd)\n",
    "                    rmse_dist = self.calculate_rmse(source_pcd, aligned_pcd)\n",
    "                    hausdorff_dist = directed_hausdorff(np.array(validation_points)[:, :3], ground_truth_points[:, :3])[0]\n",
    "                    total_loss = hausdorff_dist +rmse_dist +emd_dist\n",
    "                    \n",
    "            else:\n",
    "                total_loss += 0.001  # Add 10 to the total loss as a penalty for less than 100 validation points\n",
    "    \n",
    "        return total_loss,min_loss_value\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PointNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNetClassifier, self).__init__()\n",
    "        self.sa1 = PointNetSetAbstraction(1024, 0.1, 32, 9 + 3, [32, 32, 64], False)\n",
    "        self.sa2 = PointNetSetAbstraction(256, 0.2, 32, 64 + 3, [64, 64, 128], False)\n",
    "        self.sa3 = PointNetSetAbstraction(64, 0.4, 32, 128 + 3, [128, 128, 256], False)\n",
    "        self.transformer_layer = TransformerFeatureAbstraction(feature_dim=64, num_heads=8)\n",
    "        self.sa4 = PointNetSetAbstraction(16, 0.8, 32, 256 + 3, [256, 256, 512], False)\n",
    "        self.fp4 = PointNetFeaturePropagation(768, [256, 256])\n",
    "        self.fp3 = PointNetFeaturePropagation(384, [256, 256])\n",
    "        self.fp2 = PointNetFeaturePropagation(320, [256, 128])\n",
    "        self.fp1 = PointNetFeaturePropagation(128, [128, 128, 128])\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        l0_points = xyz\n",
    "        l0_xyz = xyz[:, :3, :]\n",
    "\n",
    "        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        # Apply Transformer to enhance features\n",
    "        l3_points = self.transformer_layer(l3_points)\n",
    "        \n",
    "        l4_xyz, l4_points = self.sa4(l3_xyz, l3_points)\n",
    "        l3_points = self.fp4(l3_xyz, l4_xyz, l3_points, l4_points)\n",
    "        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n",
    "        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n",
    "        l0_points = self.fp1(l0_xyz, l1_xyz, None, l1_points)\n",
    "\n",
    "        x = self.drop1(F.relu(self.bn1(self.conv1(l0_points))))\n",
    "        x = self.conv2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x, l4_points\n",
    "\n",
    "def read_point_cloud(file_path, chunk_size=40000):\n",
    "    points = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split()\n",
    "            if len(values) >= 6:  # Assuming XYZRGB values are present\n",
    "                point = [float(val) for val in values[:6]]  # Consider first 6 values\n",
    "                points.append(point)\n",
    "    \n",
    "    points = np.array(points)\n",
    "    points = points[points[:, 0].argsort()]  # Sort based on Y coordinate\n",
    "    \n",
    "    for i in range(0, len(points), chunk_size):\n",
    "        yield points[i:i+chunk_size]\n",
    "\n",
    "def read_point_cloud1(point_cloud_data, chunk_size=200000):\n",
    "        \"\"\"\n",
    "        Read point cloud data from a numpy array in chunks and sorts the entire array based on Y coordinate.\n",
    "        Assumes each row contains XYZRGB values.\n",
    "    \n",
    "        Args:\n",
    "        point_cloud_data (np.array): Numpy array containing point cloud data\n",
    "        chunk_size (int): Number of rows to read per chunk\n",
    "    \n",
    "        Yields:\n",
    "        np.array: Array containing point cloud data for each chunk\n",
    "        \"\"\"\n",
    "        # Sort the entire array based on the second dimension (Y coordinate)\n",
    "        points = point_cloud_data[point_cloud_data[:, 1].argsort()]  # Sort based on Y coordinate\n",
    "        \n",
    "        # Yield chunks of sorted points\n",
    "        for i in range(0, len(points), chunk_size):\n",
    "            yield points[i:i+chunk_size]\n",
    "\n",
    "\n",
    "def pad_channels(data, target_channels=9):\n",
    "    \"\"\"\n",
    "    Pad the channels of the data tensor to match the target_channels.\n",
    "    \n",
    "    Args:\n",
    "    data (torch.Tensor): Input tensor with shape [batch_size, current_channels, ...]\n",
    "    target_channels (int): Desired number of channels\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Tensor with padded channels if needed\n",
    "    \"\"\"\n",
    "    current_channels = data.shape[1]\n",
    "    if current_channels < target_channels:\n",
    "        padding_channels = target_channels - current_channels\n",
    "        padding = torch.zeros((data.shape[0], padding_channels, *data.shape[2:]), device=data.device)\n",
    "        data = torch.cat([data, padding], dim=1)\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    # Manually specify the input and output paths\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    dataset_dir = '/home/puoza/Pointnet_Pointnet2_pytorch/stanford_indoor3d'\n",
    "    chunk_size = 500000\n",
    "    num_epochs = 10  # Specify the number of epochs\n",
    "\n",
    "    # Initialize the model\n",
    "    model = PointNetClassifier(\n",
    "        num_classes=len(classes), \n",
    "    \n",
    "    ).to(device)\n",
    "    weights_path = '/home/puoza/p2/Pointnet_Pointnet2_pytorch/log/sem_seg/validator/weights_epoch_1.pth'  # Provide the correct path\n",
    "    checkpoint = torch.load(weights_path, map_location=device)\n",
    "\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    state_dict = {k: v for k, v in state_dict.items() if not k.startswith('sa3.')}\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    model.train()\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # You can adjust the learning rate as needed\n",
    "    \n",
    "    # Initialize the validator\n",
    "    validator = Validator(validator_folder='/home/puoza/Pointnet_Pointnet2_pytorch/validate')  # Replace 'path_to_validator_folder' with the actual folder path\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        scene_files = [file for file in os.listdir(dataset_dir) if file.endswith('.npy')]\n",
    "        random.shuffle(scene_files)\n",
    "\n",
    "        # Randomly shuffle the list of scene files\n",
    "        random.shuffle(scene_files)\n",
    "        for scene_file in scene_files:\n",
    "                scene_path = os.path.join(dataset_dir, scene_file)\n",
    "                scene_data = np.load(scene_path)  # Load the numpy file\n",
    "                xyzrgb_data = scene_data[:, :6]  # Extract XYZRGB data\n",
    "                \n",
    "                total_loss1 = 0.0  # Accumulate validation losses for the entire scene\n",
    "                xyzc_data_chunk=[]\n",
    "                for chunk_id, chunk_points in enumerate(read_point_cloud1(xyzrgb_data, chunk_size)):\n",
    "                    input_pc_tensor = torch.tensor(chunk_points, dtype=torch.float32).unsqueeze(0).permute(0, 2, 1).to(device)\n",
    "                    input_pc_tensor = pad_channels(input_pc_tensor, 9).to(device)\n",
    "\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output_cls,po = model(input_pc_tensor)\n",
    "                    class_predictions = output_cls.argmax(dim=2).squeeze().cpu().numpy()\n",
    "                    # Calculate validation loss\n",
    "                    xyzc_data = []  # Prepare xyzc_data\n",
    "            \n",
    "                    for i, point in enumerate(chunk_points):\n",
    "                            x, y, z, _, _, _ = point\n",
    "                            c = class_predictions[i]\n",
    "                            xyzc_data.append([x, y, z, c])\n",
    "                    xyzc_data_chunk.append(xyzc_data)\n",
    "                   \n",
    "                    # Write the predictions to a separate output file for each chunk\n",
    "                    output_chunk_path = f'/home/puoza/Pointnet_Pointnet2_pytorch/pointcloud/output_chunk_{chunk_id}.txt'\n",
    "                    if chunk_id<10:\n",
    "                        with open(output_chunk_path, 'w') as f:\n",
    "                            # Sort the points first by class and then by x-coordinate before writing\n",
    "                            sorted_indices = np.lexsort((chunk_points[:, 3], chunk_points[:, 0]))\n",
    "                            for i in sorted_indices:\n",
    "                                x, y, z, _, _, _ = chunk_points[i]\n",
    "                                c = class_predictions[i]\n",
    "                                f.write(f\"{x} {y} {z} {c}\\n\")\n",
    "            \n",
    "                    validation_loss,min_loss_value=validator.calculate_validation_loss(xyzc_data_chunk)\n",
    "                    total_loss1 = validation_loss\n",
    "                    combined_loss = total_loss1 + min_loss_value\n",
    "                    print(f\"Scene: {scene_file}, Chunk: {chunk_id}, Validation Loss: {validation_loss},min Loss: {min_loss_value}\")\n",
    "                    combined_loss_tensor = torch.tensor(combined_loss, dtype=torch.float32, requires_grad=True).to(device)\n",
    "                    combined_loss_tensor.backward()\n",
    "                    optimizer.step()\n",
    "                    weights_save_path = os.path.join('/home/puoza/p2/Pointnet_Pointnet2_pytorch/log/sem_seg/validator', f'weights_epoch_{epoch+1}.pth')\n",
    "                    torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': combined_loss_tensor.item(),\n",
    "                    }, weights_save_path)\n",
    "                    print(f\"Weights saved successfully after scene: {scene_file}\")\n",
    "                # Backpropagate using accumulated validation loss\n",
    "                \n",
    "                print(f\"Scene: {scene_file}, Total Validation Loss: {combined_loss_tensor.item()}\")\n",
    "\n",
    "# Call the main function\n",
    "main()\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b975c-00c2-431e-9819-34fd3966805d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaaba85-c6b8-48e6-86ee-c0597ccc3c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
